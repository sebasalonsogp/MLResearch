{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../models')\n",
    "sys.path.append('.../MLResearch')\n",
    "from resnet import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from resnet import ResNet18\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create the data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "nclass = 10 # number of classes\n",
    "scale = 64 # scale factor for num channels\n",
    "channels = 1 # number of input channels\n",
    "\n",
    "model = ResNet18(nclass, scale, channels, proto_layer=4,layer_norm = False, entry_stride = 1).to(device)\n",
    "\n",
    "# Define the loss function\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train on MNist,\n",
    "- Evaluate on FSHN, accuracy + fv_analysis,\n",
    "- Line graph (one graph 10 lines (MNIST, 100 lines(CIFAR))),\n",
    "- group by class, Vice-Versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(model, train_loader, dataset_name, num_epochs):\n",
    "    \n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(f'model_{dataset_name}_epoch_{num_epochs+1}.pth'))\n",
    "    model.to(device)\n",
    "\n",
    "    intra_sim,inter_sim = [],[]\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            feat_vec, _ = model(inputs)  ## get feature vectors from the model #TODO ensure that i am getting FV, not logits.\n",
    "\n",
    "            # norm_feat_vec = F.normalize(feat_vec)\n",
    "            # CosSimMatrix = torch.mm(norm_feat_vec, norm_feat_vec.t()) ## calculate cosine similarity matrix\n",
    "\n",
    "\n",
    "            for i in range(len(feat_vec)):\n",
    "                for j in range(i+1, len(feat_vec)):\n",
    "           \n",
    "                    sim = F.cosine_similarity(feat_vec[i].unsqueeze(0), feat_vec[j].unsqueeze(0)) ## calculate cosine similarity between feature vectors\n",
    "                    #sim = CosSimMatrix[i][j]\n",
    "                   \n",
    "                    if labels[i] == labels[j]:      #within class\n",
    "                        intra_sim.append(sim.item())\n",
    "                    else:                           #between class\n",
    "                        inter_sim.append(sim.item())\n",
    "                  \n",
    "    return intra_sim, inter_sim #, CosSimMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note torch.nn.functional.cosine_similarity is defined as:\n",
    " $$\n",
    "\\text{CosSim} = \\frac{\\vec{x}_1 \\cdot \\vec{x}_2}{\\max(\\|\\vec{x}_1\\|_2, \\epsilon) \\cdot \\max(\\|\\vec{x}_2\\|_2, \\epsilon)}\n",
    " $$\n",
    " where $\\epsilon$ is 1e-8 to avoid division by 0 and the magnitude is defined as $L_2$ norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, dataset_name, num_epochs):\n",
    "    \n",
    "    total_step = len(train_loader)\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            ## forward pass ##\n",
    "            outputs = model(images)\n",
    "            loss = cost(outputs, labels)\n",
    "\n",
    "            ## backwards pass and optimizer step (learning) ##\n",
    "            optimizer.zero_grad()  # zeroes out the gradients, removing exisitng ones to avoid accumulation\n",
    "            loss.backward()  # gradient of loss, how much each parameter contributed to the loss\n",
    "            optimizer.step()  # adjusts parameters based on results to minimize loss\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "        \n",
    "    torch.save(model.state_dict(), f'model_{dataset_name}_epoch_{num_epochs+1}.pth') #save after training        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(model, train_loader, optimizer, 'mnist', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cos_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m intra_sim, inter_sim \u001b[38;5;241m=\u001b[39m \u001b[43mcos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m intra_sim_np, inter_sim_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(intra_sim), np\u001b[38;5;241m.\u001b[39marray(inter_sim)\n",
      "Cell \u001b[1;32mIn[18], line 26\u001b[0m, in \u001b[0;36mcos_sim\u001b[1;34m(model, train_loader, dataset_name, num_epochs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(feat_vec)):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feat_vec)):\n\u001b[1;32m---> 26\u001b[0m         sim \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat_vec\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_vec\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m## calculate cosine similarity between feature vectors\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;66;03m#sim = CosSimMatrix[i][j]\u001b[39;00m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m labels[i] \u001b[38;5;241m==\u001b[39m labels[j]:      \u001b[38;5;66;03m#within class\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "intra_sim, inter_sim = cos_sim(model, train_loader, 'mnist', num_epochs)\n",
    "intra_sim_np, inter_sim_np = np.array(intra_sim), np.array(inter_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res(intra_sim_np, inter_sim_np):\n",
    "    print(f\"Intra-class Similarity: {intra_sim_np}\\nInter-class Similarity: {inter_sim_np}]\\n\")\n",
    "    print(f\"Inter-class Similarity: Mean = {inter_sim_np.mean()}, Std = {inter_sim_np.std()}, Var = {np.var(inter_sim)}\\nIntra-class similarity: Mean = {intra_sim_np.mean()}, Std = {intra_sim_np.std()}, Var = {np.var(intra_sim)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intra_sim_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m print_res(\u001b[43mintra_sim_np\u001b[49m, inter_sim_np)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'intra_sim_np' is not defined"
     ]
    }
   ],
   "source": [
    "print_res(intra_sim_np, inter_sim_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(intra_sim_np, inter_sim_np):\n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    #Intra-class similarity\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.hist(intra_sim_np, bins=50, color='blue', edgecolor='black', alpha=0.5)\n",
    "    plt.title(\"Intra-class cosine similarity\")\n",
    "    plt.xlabel(\"Cosine similarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    #Inter-class similarity\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.hist(inter_sim_np, bins=50, color='red', edgecolor='black', alpha=0.5)\n",
    "    plt.title(\"Inter-class cosine similarity\")\n",
    "    plt.xlabel(\"Cosine similarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(intra_sim_np, inter_sim_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(intra_sim,inter_sim,sample_size=1000):\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(14,7))\n",
    "\n",
    "    intra_indices = np.random.choice(range(len(intra_sim)), sample_size, replace=False)\n",
    "    inter_indices = np.random.choice(range(len(inter_sim)), sample_size, replace=False) \n",
    "\n",
    "    intra_class_sample = np.array(intra_sim)[intra_indices]\n",
    "    inter_class_sample = np.array(inter_sim)[inter_indices]\n",
    "    \n",
    "\n",
    "    plt.scatter(intra_indices, intra_class_sample, color='blue', alpha=0.1, label='Intra-class',s=5)\n",
    "    plt.scatter(inter_indices, inter_class_sample, color='red', alpha=0.2, label='Inter-class',s=10)\n",
    "\n",
    "    plt.title(\"cosine similarity scatter plot\")\n",
    "    plt.xlabel(\"index\")\n",
    "    plt.ylabel(\"Cosine Similarity\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def agg_scatter(intra_sim_np, inter_sim_np, bin_size=100):\n",
    "    cos_sim = np.concatenate((intra_sim_np, inter_sim_np))\n",
    "    \n",
    "    binned_means = [np.mean(cos_sim[i:i+bin_size]) for i in range(0, len(cos_sim), bin_size)]\n",
    "\n",
    "    plt.figure(figsize=(14,7))\n",
    "\n",
    "    plt.scatter(range(0,len(cos_sim),bin_size), binned_means, color='blue', alpha=0.1, s=1)\n",
    "    plt.title(\"Cosine similarity between feature vectors\")\n",
    "    plt.xlabel(\"Bin Index\")\n",
    "    plt.ylabel(\"Mean Cosine Similarity\")\n",
    "    plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(intra_sim_np,inter_sim_np)\n",
    "agg_scatter(intra_sim_np, inter_sim_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet -- Cifar10\n",
    "define new model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "cifar_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create the data loader\n",
    "cifar_train_loader = torch.utils.data.DataLoader(cifar_train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the number of classes\n",
    "cifar_nclass = 10\n",
    "cifar_scale = 32\n",
    "cifar_channels = 3\n",
    "\n",
    "# Create an instance of ResNet18 model\n",
    "cifar_model = ResNet18(cifar_nclass, cifar_scale, cifar_channels, proto_layer=4,layer_norm = False, entry_stride = 1).to(device)\n",
    "\n",
    "#Define optimizer\n",
    "cifar_optimizer = optim.SGD(cifar_model.parameters(), lr=0.01)\n",
    "\n",
    "cifar_num_epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(cifar_model, cifar_train_loader, cifar_optimizer, 'cifar10', cifar_num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cifar_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cifar_intra_sim, cifar_inter_sim \u001b[38;5;241m=\u001b[39m cos_sim(\u001b[43mcifar_model\u001b[49m, cifar_train_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar10\u001b[39m\u001b[38;5;124m'\u001b[39m,cifar_num_epochs)\n\u001b[0;32m      2\u001b[0m cifar_intra_sim_np, cifar_inter_sim_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(cifar_intra_sim), np\u001b[38;5;241m.\u001b[39marray(cifar_inter_sim)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cifar_model' is not defined"
     ]
    }
   ],
   "source": [
    "cifar_intra_sim, cifar_inter_sim = cos_sim(cifar_model, cifar_train_loader, 'cifar10',cifar_num_epochs)\n",
    "cifar_intra_sim_np, cifar_inter_sim_np = np.array(cifar_intra_sim), np.array(cifar_inter_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(cifar_intra_sim_np, cifar_inter_sim_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(cifar_intra_sim_np, cifar_inter_sim_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(cifar_intra_sim_np, cifar_inter_sim_np)\n",
    "agg_scatter(cifar_intra_sim_np, cifar_inter_sim_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet - Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from densenet import DenseNetCifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_nclasses = 10\n",
    "dn_scale = 32\n",
    "dn_channels = 3\n",
    "dn_cifar_num_epochs = 50\n",
    "dn_model = DenseNetCifar(dn_nclasses, dn_scale, dn_channels, proto_layer=4,layer_norm = False, entry_stride = 1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(dn_model, cifar_train_loader, cifar_optimizer, 'dn_cifar10', dn_cifar_num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
